{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Tensor flow are array manipulation library.\n",
    "\n",
    "**Tensor** and size dimension array\n",
    "\n",
    "**Tensorflow** functions on tensors. \n",
    "\n",
    "**Tensorflow** a deep learning library more like numpy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = tf.constant(5)\n",
    "x2 = tf.constant(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf.multiply(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# starting and running a session\n",
    "\n",
    "sess = tf.Session()  #start\n",
    "print(sess.run(result))\n",
    "sess.close()         #close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# no closing required  Computation graph of your architecture\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(result)\n",
    "    print(type(output))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/siavashmortezavi/train-images-idx3-ubyte.gz\n",
      "Extracting /data/siavashmortezavi/train-labels-idx1-ubyte.gz\n",
      "Extracting /data/siavashmortezavi/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/siavashmortezavi/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSince one_hot = True\\nchanges the output to be\\n\\n0 = [1,0,0,0,0,0,0,0,0,0]\\n1 = [0,1,0,0,0,0,0,0,0,0]\\n2 = [0,0,1,0,0,0,0,0,0,0]\\n3 = [0,0,0,1,0,0,0,0,0,0]\\n4 = [0,0,0,0,1,0,0,0,0,0]\\n5 = [0,0,0,0,0,1,0,0,0,0]\\n6 = [0,0,0,0,0,0,1,0,0,0]\\n7 = [0,0,0,0,0,0,0,1,0,0]\\n8 = [0,0,0,0,0,0,0,0,1,0]\\n9 = [0,0,0,0,0,0,0,0,0,1]\\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "(feed forward)\n",
    "input > weight > hidden layer 1(activation function) > weights > hidden l 2\n",
    "(activation function) > weigths > ouput layer \n",
    "\n",
    "compare output to intended output > cost or less function (cross entropy)\n",
    "optimizaton function (optimizer) > minimize cost (AdamOptimizer .. SGD, AdaGrad)\n",
    "\n",
    "back propagation\n",
    "\n",
    "feed forward + backprop = epoch\n",
    "\"\"\"\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/data/siavashmortezavi/\", one_hot=True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Since one_hot = True\n",
    "changes the output to be\n",
    "\n",
    "0 = [1,0,0,0,0,0,0,0,0,0]\n",
    "1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "2 = [0,0,1,0,0,0,0,0,0,0]\n",
    "3 = [0,0,0,1,0,0,0,0,0,0]\n",
    "4 = [0,0,0,0,1,0,0,0,0,0]\n",
    "5 = [0,0,0,0,0,1,0,0,0,0]\n",
    "6 = [0,0,0,0,0,0,1,0,0,0]\n",
    "7 = [0,0,0,0,0,0,0,1,0,0]\n",
    "8 = [0,0,0,0,0,0,0,0,1,0]\n",
    "9 = [0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nodes per hidden layer\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of classes \n",
    "n_classes = 10\n",
    "#choose how many images to be fed per epoch\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height x width\n",
    "# by leaving the the extra [None, 784] parameter tensor flow will throw an \n",
    "# error if you attempt to feed a shape that is different from intended shape\n",
    "x = tf.placeholder('float', [None,784]) #flatten 28 by 28\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    #two values, weights are variables initialized with random normals\n",
    "    #   biases,\n",
    "    # (input_data * weights) + bias, if no input_data allows for activation\n",
    "    hidden_1_layer = {'weights':tf.Variable(\\\n",
    "    tf.random_normal([784, n_nodes_hl1])),'biases':\\\n",
    "                      tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    hidden_2_layer = {'weights':tf.Variable(\\\n",
    "    tf.random_normal([n_nodes_hl1, n_nodes_hl2])),'biases':\\\n",
    "                      tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    hidden_3_layer = {'weights':tf.Variable(\\\n",
    "    tf.random_normal([n_nodes_hl2, n_nodes_hl3])),'biases':\\\n",
    "                      tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    output_layer = {'weights':tf.Variable(\\\n",
    "    tf.random_normal([n_nodes_hl3, n_classes])),'biases':\\\n",
    "                      tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    # (input_data * weights) + bias, if no input_data allows for activation\n",
    "    l1 = tf.add(\\\n",
    "         tf.matmul(data,hidden_1_layer['weights'])\\\n",
    "         ,hidden_1_layer['biases'])\n",
    "    #threshold/activation function\n",
    "    l1 = tf.nn.relu(l1)\n",
    "   \n",
    "\n",
    "    l2 = tf.add(\\\n",
    "         tf.matmul(l1,hidden_2_layer['weights'])\\\n",
    "         ,hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    \n",
    "    l3 = tf.add(\\\n",
    "         tf.matmul(l2,hidden_3_layer['weights'])\\\n",
    "         ,hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.add(\\\n",
    "         tf.matmul(l3,output_layer['weights'])\\\n",
    "         ,output_layer['biases'])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction,labels = y))\n",
    "    #minimizing cost\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    #cycles of feed forwad and backprop\n",
    "    num_epochs = 20\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "      #training  \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0 \n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer,cost], feed_dict={x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "            print('Epoch', epoch, 'completed out of', num_epochs, 'loss', epoch_loss)\n",
    "        \n",
    "        #tf.argmax returns the index of the highest value,     \n",
    "       \n",
    "    \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy  = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/siavashmortezavi/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of 20 loss 1745113.41988\n",
      "Epoch 1 completed out of 20 loss 407793.022132\n",
      "Epoch 2 completed out of 20 loss 224853.788911\n",
      "Epoch 3 completed out of 20 loss 134396.55987\n",
      "Epoch 4 completed out of 20 loss 80169.607007\n",
      "Epoch 5 completed out of 20 loss 55193.3430054\n",
      "Epoch 6 completed out of 20 loss 36106.0340863\n",
      "Epoch 7 completed out of 20 loss 26446.5727291\n",
      "Epoch 8 completed out of 20 loss 21110.753469\n",
      "Epoch 9 completed out of 20 loss 17689.9407884\n",
      "Epoch 10 completed out of 20 loss 17639.5399736\n",
      "Epoch 11 completed out of 20 loss 13814.2531864\n",
      "Epoch 12 completed out of 20 loss 16952.0756474\n",
      "Epoch 13 completed out of 20 loss 13715.4574219\n",
      "Epoch 14 completed out of 20 loss 11999.0836322\n",
      "Epoch 15 completed out of 20 loss 11630.4372842\n",
      "Epoch 16 completed out of 20 loss 9078.3577147\n",
      "Epoch 17 completed out of 20 loss 9523.97608059\n",
      "Epoch 18 completed out of 20 loss 10453.5428534\n",
      "Epoch 19 completed out of 20 loss 10724.0178974\n",
      "Accuracy: 0.9606\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
